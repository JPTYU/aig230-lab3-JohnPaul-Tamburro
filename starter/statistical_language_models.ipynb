{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91489c36",
   "metadata": {},
   "source": [
    "# AIG230 NLP (Week 3 Lab) â€” Notebook 2: Statistical Language Models (Train, Test, Evaluate)\n",
    "\n",
    "This notebook focuses on **n-gram Statistical Language Models (SLMs)**:\n",
    "- Train **unigram**, **bigram**, **trigram** models\n",
    "- Handle **OOV** with `<UNK>`\n",
    "- Apply **smoothing** (Add-k)\n",
    "- Evaluate with **cross-entropy** and **perplexity**\n",
    "- Do **next-word prediction** and simple **text generation**\n",
    "\n",
    "> Industry framing: even if modern systems use neural LMs, n-gram LMs are still useful for\n",
    "baselines, constrained domains, and for understanding evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a046e",
   "metadata": {},
   "source": [
    "## 0) Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc428b4",
   "metadata": {},
   "source": [
    "## 1) Data: domain text you might see in real systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d207e4c",
   "metadata": {},
   "source": [
    "We use short texts that resemble:\n",
    "- release notes\n",
    "- incident summaries\n",
    "- operational runbooks\n",
    "- customer support messaging\n",
    "\n",
    "In practice, you would load thousands to millions of lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdb34582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,\n",
       " 10,\n",
       " ['firewall blocking access to external resources',\n",
       "  'geolocation service inaccurate location data'],\n",
       " ['mailbox full cannot receive emails auto archive not running',\n",
       "  'network latency high affecting user experience'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corpus = [\n",
    "    \"vpn disconnects frequently after windows update\",\n",
    "    \"password reset link expired user cannot login\",\n",
    "    \"api requests timeout when latency spikes\",\n",
    "    \"portal returns 500 error after deployment\",\n",
    "    \"email delivery delayed messages queued\",\n",
    "    \"mfa prompt never arrives user stuck at login\",\n",
    "    \"wifi drops in meeting rooms access point reboot helps\",\n",
    "    \"outlook search not returning results index corrupted\",\n",
    "    \"printer driver install fails with error 1603\",\n",
    "    \"teams calls choppy audio jitter high\",\n",
    "    \"permission denied accessing shared drive though in correct group\",\n",
    "    \"battery drains fast after bios update power settings unchanged\",\n",
    "    \"push notifications not working on android app\",\n",
    "    \"mailbox full cannot receive emails auto archive not running\",\n",
    "    \"server overloaded capacity reached\",\n",
    "    \"database connection lost service unavailable\",\n",
    "    \"disk space low performance degraded\",\n",
    "    \"application crashed unexpectedly log analysis needed\",\n",
    "    \"network latency high affecting user experience\",\n",
    "    \"authentication failed invalid credentials provided\",\n",
    "    \"storage quota exceeded cannot upload files\",\n",
    "    \"memory leak detected service restarting\",\n",
    "    \"cpu utilization spiking abnormal process activity\",\n",
    "    \"firewall blocking access to external resources\",\n",
    "    \"dns resolution failing domain not found\",\n",
    "    \"load balancer misconfigured traffic routing issues\",\n",
    "    \"certificate expired secure connection failed\",\n",
    "    \"backup process failed data integrity compromised\",\n",
    "    \"monitoring system alert threshold breached\",\n",
    "    \"container exited unexpectedly check logs\",\n",
    "    \"queue full message processing stalled\",\n",
    "    \"api key invalid access denied\",\n",
    "    \"firmware update failed device unresponsive\",\n",
    "    \"geolocation service inaccurate location data\",\n",
    "    \"billing discrepancy incorrect invoice generated\",\n",
    "    \"user interface unresponsive freezing on interactions\",\n",
    "    \"data synchronization error inconsistent records\",\n",
    "    \"scheduler failed tasks not executing\",\n",
    "    \"encryption key missing secure communication impossible\"\n",
    "]\n",
    "\n",
    "# Train/test split at sentence level\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "split = int(0.75 * len(corpus))\n",
    "train_texts = corpus[:split]\n",
    "test_texts = corpus[split:]\n",
    "\n",
    "len(train_texts), len(test_texts), train_texts[:2], test_texts[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f9947",
   "metadata": {},
   "source": [
    "## 2) Tokenization + special tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c285f1d",
   "metadata": {},
   "source": [
    "We will:\n",
    "- lowercase\n",
    "- keep alphanumerics\n",
    "- split on whitespace\n",
    "- add sentence boundary tokens: `<s>` and `</s>`\n",
    "\n",
    "We will also map rare tokens to `<UNK>` based on training frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "058f87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'printer',\n",
       " 'driver',\n",
       " 'install',\n",
       " 'fails',\n",
       " 'with',\n",
       " 'error',\n",
       " '1603',\n",
       " '</s>']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.split()\n",
    "\n",
    "def add_boundaries(tokens: List[str], n: int) -> List[str]:\n",
    "    # For n-grams, prepend (n-1) start tokens for simpler context handling\n",
    "    return [\"<s>\"]*(n-1) + tokens + [\"</s>\"]\n",
    "\n",
    "# Example\n",
    "tokens = tokenize(\"Printer driver install fails with error 1603\")\n",
    "add_boundaries(tokens, n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25308557",
   "metadata": {},
   "source": [
    "## 3) Build vocabulary and handle OOV with <UNK>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3338f0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mailbox',\n",
       "  'full',\n",
       "  'cannot',\n",
       "  'receive',\n",
       "  'emails',\n",
       "  'auto',\n",
       "  'archive',\n",
       "  'not',\n",
       "  'running'],\n",
       " ['<UNK>',\n",
       "  'full',\n",
       "  'cannot',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'not',\n",
       "  '<UNK>'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build vocab from training data\n",
    "train_tokens_flat = []\n",
    "for t in train_texts:\n",
    "    train_tokens_flat.extend(tokenize(t))\n",
    "\n",
    "freq = Counter(train_tokens_flat)\n",
    "\n",
    "# Typical practical rule: map tokens with frequency <= 1 to <UNK> in small corpora\n",
    "min_count = 1\n",
    "vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "vocab |= {\"<UNK>\", \"<s>\", \"</s>\"}\n",
    "\n",
    "def replace_oov(tokens: List[str], vocab: set) -> List[str]:\n",
    "    return [tok if tok in vocab else \"<UNK>\" for tok in tokens]\n",
    "\n",
    "# Show OOV effect\n",
    "sample = tokenize(test_texts[0])\n",
    "sample, replace_oov(sample, vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759444a0",
   "metadata": {},
   "source": [
    "## 4) Train n-gram counts (unigram, bigram, trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eac8fa",
   "metadata": {},
   "source": [
    "We will compute:\n",
    "- `ngram_counts[(w1,...,wn)]`\n",
    "- `context_counts[(w1,...,w_{n-1})]`\n",
    "\n",
    "Then probability:\n",
    "\\ndefault:  P(w_n | context) = count(context + w_n) / count(context)\n",
    "\n",
    "This fails when an n-gram is unseen, so we add smoothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33672bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(tokens: List[str], n: int) -> List[Tuple[str, ...]]:\n",
    "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "def train_ngrams_counts(texts: List[str], n: int, vocab: set) -> Dict[Tuple[str, ...], int]:\n",
    "    ngram_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "    for t in texts:\n",
    "        tokens = replace_oov(tokenize(t), vocab)\n",
    "        tokens = add_boundaries(tokens, n)\n",
    "        ngrams = get_ngrams(tokens, n)\n",
    "        for ng in ngrams:\n",
    "            ngram_counts[ng] += 1\n",
    "            context = ng[:-1]\n",
    "            context_counts[context] += 1\n",
    "    return ngram_counts, context_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ad0e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_counts, uni_ctx = train_ngrams_counts(train_texts, 1, vocab) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e2d46936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('</s>',): 29,\n",
       "         ('failed',): 5,\n",
       "         ('data',): 3,\n",
       "         ('after',): 3,\n",
       "         ('update',): 3,\n",
       "         ('not',): 3,\n",
       "         ('access',): 2,\n",
       "         ('service',): 2,\n",
       "         ('error',): 2,\n",
       "         ('denied',): 2,\n",
       "         ('unresponsive',): 2,\n",
       "         ('on',): 2,\n",
       "         ('api',): 2,\n",
       "         ('key',): 2,\n",
       "         ('invalid',): 2,\n",
       "         ('process',): 2,\n",
       "         ('secure',): 2,\n",
       "         ('firewall',): 1,\n",
       "         ('blocking',): 1,\n",
       "         ('to',): 1,\n",
       "         ('external',): 1,\n",
       "         ('resources',): 1,\n",
       "         ('geolocation',): 1,\n",
       "         ('inaccurate',): 1,\n",
       "         ('location',): 1,\n",
       "         ('portal',): 1,\n",
       "         ('returns',): 1,\n",
       "         ('500',): 1,\n",
       "         ('deployment',): 1,\n",
       "         ('battery',): 1,\n",
       "         ('drains',): 1,\n",
       "         ('fast',): 1,\n",
       "         ('bios',): 1,\n",
       "         ('power',): 1,\n",
       "         ('settings',): 1,\n",
       "         ('unchanged',): 1,\n",
       "         ('permission',): 1,\n",
       "         ('accessing',): 1,\n",
       "         ('shared',): 1,\n",
       "         ('drive',): 1,\n",
       "         ('though',): 1,\n",
       "         ('in',): 1,\n",
       "         ('correct',): 1,\n",
       "         ('group',): 1,\n",
       "         ('user',): 1,\n",
       "         ('interface',): 1,\n",
       "         ('freezing',): 1,\n",
       "         ('interactions',): 1,\n",
       "         ('monitoring',): 1,\n",
       "         ('system',): 1,\n",
       "         ('alert',): 1,\n",
       "         ('threshold',): 1,\n",
       "         ('breached',): 1,\n",
       "         ('queue',): 1,\n",
       "         ('full',): 1,\n",
       "         ('message',): 1,\n",
       "         ('processing',): 1,\n",
       "         ('stalled',): 1,\n",
       "         ('cpu',): 1,\n",
       "         ('utilization',): 1,\n",
       "         ('spiking',): 1,\n",
       "         ('abnormal',): 1,\n",
       "         ('activity',): 1,\n",
       "         ('certificate',): 1,\n",
       "         ('expired',): 1,\n",
       "         ('connection',): 1,\n",
       "         ('memory',): 1,\n",
       "         ('leak',): 1,\n",
       "         ('detected',): 1,\n",
       "         ('restarting',): 1,\n",
       "         ('push',): 1,\n",
       "         ('notifications',): 1,\n",
       "         ('working',): 1,\n",
       "         ('android',): 1,\n",
       "         ('app',): 1,\n",
       "         ('email',): 1,\n",
       "         ('delivery',): 1,\n",
       "         ('delayed',): 1,\n",
       "         ('messages',): 1,\n",
       "         ('queued',): 1,\n",
       "         ('teams',): 1,\n",
       "         ('calls',): 1,\n",
       "         ('choppy',): 1,\n",
       "         ('audio',): 1,\n",
       "         ('jitter',): 1,\n",
       "         ('high',): 1,\n",
       "         ('billing',): 1,\n",
       "         ('discrepancy',): 1,\n",
       "         ('incorrect',): 1,\n",
       "         ('invoice',): 1,\n",
       "         ('generated',): 1,\n",
       "         ('dns',): 1,\n",
       "         ('resolution',): 1,\n",
       "         ('failing',): 1,\n",
       "         ('domain',): 1,\n",
       "         ('found',): 1,\n",
       "         ('container',): 1,\n",
       "         ('exited',): 1,\n",
       "         ('unexpectedly',): 1,\n",
       "         ('check',): 1,\n",
       "         ('logs',): 1,\n",
       "         ('storage',): 1,\n",
       "         ('quota',): 1,\n",
       "         ('exceeded',): 1,\n",
       "         ('cannot',): 1,\n",
       "         ('upload',): 1,\n",
       "         ('files',): 1,\n",
       "         ('load',): 1,\n",
       "         ('balancer',): 1,\n",
       "         ('misconfigured',): 1,\n",
       "         ('traffic',): 1,\n",
       "         ('routing',): 1,\n",
       "         ('issues',): 1,\n",
       "         ('synchronization',): 1,\n",
       "         ('inconsistent',): 1,\n",
       "         ('records',): 1,\n",
       "         ('backup',): 1,\n",
       "         ('integrity',): 1,\n",
       "         ('compromised',): 1,\n",
       "         ('authentication',): 1,\n",
       "         ('credentials',): 1,\n",
       "         ('provided',): 1,\n",
       "         ('disk',): 1,\n",
       "         ('space',): 1,\n",
       "         ('low',): 1,\n",
       "         ('performance',): 1,\n",
       "         ('degraded',): 1,\n",
       "         ('encryption',): 1,\n",
       "         ('missing',): 1,\n",
       "         ('communication',): 1,\n",
       "         ('impossible',): 1,\n",
       "         ('firmware',): 1,\n",
       "         ('device',): 1,\n",
       "         ('requests',): 1,\n",
       "         ('timeout',): 1,\n",
       "         ('when',): 1,\n",
       "         ('latency',): 1,\n",
       "         ('spikes',): 1,\n",
       "         ('vpn',): 1,\n",
       "         ('disconnects',): 1,\n",
       "         ('frequently',): 1,\n",
       "         ('windows',): 1,\n",
       "         ('scheduler',): 1,\n",
       "         ('tasks',): 1,\n",
       "         ('executing',): 1})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c95e7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_counts, bi_ctx = train_ngrams_counts(train_texts, 2, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e493de90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<s>', 'api'): 2,\n",
       "         ('<s>', 'firewall'): 1,\n",
       "         ('firewall', 'blocking'): 1,\n",
       "         ('blocking', 'access'): 1,\n",
       "         ('access', 'to'): 1,\n",
       "         ('to', 'external'): 1,\n",
       "         ('external', 'resources'): 1,\n",
       "         ('resources', '</s>'): 1,\n",
       "         ('<s>', 'geolocation'): 1,\n",
       "         ('geolocation', 'service'): 1,\n",
       "         ('service', 'inaccurate'): 1,\n",
       "         ('inaccurate', 'location'): 1,\n",
       "         ('location', 'data'): 1,\n",
       "         ('data', '</s>'): 1,\n",
       "         ('<s>', 'portal'): 1,\n",
       "         ('portal', 'returns'): 1,\n",
       "         ('returns', '500'): 1,\n",
       "         ('500', 'error'): 1,\n",
       "         ('error', 'after'): 1,\n",
       "         ('after', 'deployment'): 1,\n",
       "         ('deployment', '</s>'): 1,\n",
       "         ('<s>', 'battery'): 1,\n",
       "         ('battery', 'drains'): 1,\n",
       "         ('drains', 'fast'): 1,\n",
       "         ('fast', 'after'): 1,\n",
       "         ('after', 'bios'): 1,\n",
       "         ('bios', 'update'): 1,\n",
       "         ('update', 'power'): 1,\n",
       "         ('power', 'settings'): 1,\n",
       "         ('settings', 'unchanged'): 1,\n",
       "         ('unchanged', '</s>'): 1,\n",
       "         ('<s>', 'permission'): 1,\n",
       "         ('permission', 'denied'): 1,\n",
       "         ('denied', 'accessing'): 1,\n",
       "         ('accessing', 'shared'): 1,\n",
       "         ('shared', 'drive'): 1,\n",
       "         ('drive', 'though'): 1,\n",
       "         ('though', 'in'): 1,\n",
       "         ('in', 'correct'): 1,\n",
       "         ('correct', 'group'): 1,\n",
       "         ('group', '</s>'): 1,\n",
       "         ('<s>', 'user'): 1,\n",
       "         ('user', 'interface'): 1,\n",
       "         ('interface', 'unresponsive'): 1,\n",
       "         ('unresponsive', 'freezing'): 1,\n",
       "         ('freezing', 'on'): 1,\n",
       "         ('on', 'interactions'): 1,\n",
       "         ('interactions', '</s>'): 1,\n",
       "         ('<s>', 'monitoring'): 1,\n",
       "         ('monitoring', 'system'): 1,\n",
       "         ('system', 'alert'): 1,\n",
       "         ('alert', 'threshold'): 1,\n",
       "         ('threshold', 'breached'): 1,\n",
       "         ('breached', '</s>'): 1,\n",
       "         ('<s>', 'queue'): 1,\n",
       "         ('queue', 'full'): 1,\n",
       "         ('full', 'message'): 1,\n",
       "         ('message', 'processing'): 1,\n",
       "         ('processing', 'stalled'): 1,\n",
       "         ('stalled', '</s>'): 1,\n",
       "         ('api', 'key'): 1,\n",
       "         ('key', 'invalid'): 1,\n",
       "         ('invalid', 'access'): 1,\n",
       "         ('access', 'denied'): 1,\n",
       "         ('denied', '</s>'): 1,\n",
       "         ('<s>', 'cpu'): 1,\n",
       "         ('cpu', 'utilization'): 1,\n",
       "         ('utilization', 'spiking'): 1,\n",
       "         ('spiking', 'abnormal'): 1,\n",
       "         ('abnormal', 'process'): 1,\n",
       "         ('process', 'activity'): 1,\n",
       "         ('activity', '</s>'): 1,\n",
       "         ('<s>', 'certificate'): 1,\n",
       "         ('certificate', 'expired'): 1,\n",
       "         ('expired', 'secure'): 1,\n",
       "         ('secure', 'connection'): 1,\n",
       "         ('connection', 'failed'): 1,\n",
       "         ('failed', '</s>'): 1,\n",
       "         ('<s>', 'memory'): 1,\n",
       "         ('memory', 'leak'): 1,\n",
       "         ('leak', 'detected'): 1,\n",
       "         ('detected', 'service'): 1,\n",
       "         ('service', 'restarting'): 1,\n",
       "         ('restarting', '</s>'): 1,\n",
       "         ('<s>', 'push'): 1,\n",
       "         ('push', 'notifications'): 1,\n",
       "         ('notifications', 'not'): 1,\n",
       "         ('not', 'working'): 1,\n",
       "         ('working', 'on'): 1,\n",
       "         ('on', 'android'): 1,\n",
       "         ('android', 'app'): 1,\n",
       "         ('app', '</s>'): 1,\n",
       "         ('<s>', 'email'): 1,\n",
       "         ('email', 'delivery'): 1,\n",
       "         ('delivery', 'delayed'): 1,\n",
       "         ('delayed', 'messages'): 1,\n",
       "         ('messages', 'queued'): 1,\n",
       "         ('queued', '</s>'): 1,\n",
       "         ('<s>', 'teams'): 1,\n",
       "         ('teams', 'calls'): 1,\n",
       "         ('calls', 'choppy'): 1,\n",
       "         ('choppy', 'audio'): 1,\n",
       "         ('audio', 'jitter'): 1,\n",
       "         ('jitter', 'high'): 1,\n",
       "         ('high', '</s>'): 1,\n",
       "         ('<s>', 'billing'): 1,\n",
       "         ('billing', 'discrepancy'): 1,\n",
       "         ('discrepancy', 'incorrect'): 1,\n",
       "         ('incorrect', 'invoice'): 1,\n",
       "         ('invoice', 'generated'): 1,\n",
       "         ('generated', '</s>'): 1,\n",
       "         ('<s>', 'dns'): 1,\n",
       "         ('dns', 'resolution'): 1,\n",
       "         ('resolution', 'failing'): 1,\n",
       "         ('failing', 'domain'): 1,\n",
       "         ('domain', 'not'): 1,\n",
       "         ('not', 'found'): 1,\n",
       "         ('found', '</s>'): 1,\n",
       "         ('<s>', 'container'): 1,\n",
       "         ('container', 'exited'): 1,\n",
       "         ('exited', 'unexpectedly'): 1,\n",
       "         ('unexpectedly', 'check'): 1,\n",
       "         ('check', 'logs'): 1,\n",
       "         ('logs', '</s>'): 1,\n",
       "         ('<s>', 'storage'): 1,\n",
       "         ('storage', 'quota'): 1,\n",
       "         ('quota', 'exceeded'): 1,\n",
       "         ('exceeded', 'cannot'): 1,\n",
       "         ('cannot', 'upload'): 1,\n",
       "         ('upload', 'files'): 1,\n",
       "         ('files', '</s>'): 1,\n",
       "         ('<s>', 'load'): 1,\n",
       "         ('load', 'balancer'): 1,\n",
       "         ('balancer', 'misconfigured'): 1,\n",
       "         ('misconfigured', 'traffic'): 1,\n",
       "         ('traffic', 'routing'): 1,\n",
       "         ('routing', 'issues'): 1,\n",
       "         ('issues', '</s>'): 1,\n",
       "         ('<s>', 'data'): 1,\n",
       "         ('data', 'synchronization'): 1,\n",
       "         ('synchronization', 'error'): 1,\n",
       "         ('error', 'inconsistent'): 1,\n",
       "         ('inconsistent', 'records'): 1,\n",
       "         ('records', '</s>'): 1,\n",
       "         ('<s>', 'backup'): 1,\n",
       "         ('backup', 'process'): 1,\n",
       "         ('process', 'failed'): 1,\n",
       "         ('failed', 'data'): 1,\n",
       "         ('data', 'integrity'): 1,\n",
       "         ('integrity', 'compromised'): 1,\n",
       "         ('compromised', '</s>'): 1,\n",
       "         ('<s>', 'authentication'): 1,\n",
       "         ('authentication', 'failed'): 1,\n",
       "         ('failed', 'invalid'): 1,\n",
       "         ('invalid', 'credentials'): 1,\n",
       "         ('credentials', 'provided'): 1,\n",
       "         ('provided', '</s>'): 1,\n",
       "         ('<s>', 'disk'): 1,\n",
       "         ('disk', 'space'): 1,\n",
       "         ('space', 'low'): 1,\n",
       "         ('low', 'performance'): 1,\n",
       "         ('performance', 'degraded'): 1,\n",
       "         ('degraded', '</s>'): 1,\n",
       "         ('<s>', 'encryption'): 1,\n",
       "         ('encryption', 'key'): 1,\n",
       "         ('key', 'missing'): 1,\n",
       "         ('missing', 'secure'): 1,\n",
       "         ('secure', 'communication'): 1,\n",
       "         ('communication', 'impossible'): 1,\n",
       "         ('impossible', '</s>'): 1,\n",
       "         ('<s>', 'firmware'): 1,\n",
       "         ('firmware', 'update'): 1,\n",
       "         ('update', 'failed'): 1,\n",
       "         ('failed', 'device'): 1,\n",
       "         ('device', 'unresponsive'): 1,\n",
       "         ('unresponsive', '</s>'): 1,\n",
       "         ('api', 'requests'): 1,\n",
       "         ('requests', 'timeout'): 1,\n",
       "         ('timeout', 'when'): 1,\n",
       "         ('when', 'latency'): 1,\n",
       "         ('latency', 'spikes'): 1,\n",
       "         ('spikes', '</s>'): 1,\n",
       "         ('<s>', 'vpn'): 1,\n",
       "         ('vpn', 'disconnects'): 1,\n",
       "         ('disconnects', 'frequently'): 1,\n",
       "         ('frequently', 'after'): 1,\n",
       "         ('after', 'windows'): 1,\n",
       "         ('windows', 'update'): 1,\n",
       "         ('update', '</s>'): 1,\n",
       "         ('<s>', 'scheduler'): 1,\n",
       "         ('scheduler', 'failed'): 1,\n",
       "         ('failed', 'tasks'): 1,\n",
       "         ('tasks', 'not'): 1,\n",
       "         ('not', 'executing'): 1,\n",
       "         ('executing', '</s>'): 1})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab0f89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_counts, tri_ctx = train_ngrams_counts(train_texts, 3, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfec6938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<s>', '<s>', 'api'): 2,\n",
       "         ('<s>', '<s>', 'firewall'): 1,\n",
       "         ('<s>', 'firewall', 'blocking'): 1,\n",
       "         ('firewall', 'blocking', 'access'): 1,\n",
       "         ('blocking', 'access', 'to'): 1,\n",
       "         ('access', 'to', 'external'): 1,\n",
       "         ('to', 'external', 'resources'): 1,\n",
       "         ('external', 'resources', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'geolocation'): 1,\n",
       "         ('<s>', 'geolocation', 'service'): 1,\n",
       "         ('geolocation', 'service', 'inaccurate'): 1,\n",
       "         ('service', 'inaccurate', 'location'): 1,\n",
       "         ('inaccurate', 'location', 'data'): 1,\n",
       "         ('location', 'data', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'portal'): 1,\n",
       "         ('<s>', 'portal', 'returns'): 1,\n",
       "         ('portal', 'returns', '500'): 1,\n",
       "         ('returns', '500', 'error'): 1,\n",
       "         ('500', 'error', 'after'): 1,\n",
       "         ('error', 'after', 'deployment'): 1,\n",
       "         ('after', 'deployment', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'battery'): 1,\n",
       "         ('<s>', 'battery', 'drains'): 1,\n",
       "         ('battery', 'drains', 'fast'): 1,\n",
       "         ('drains', 'fast', 'after'): 1,\n",
       "         ('fast', 'after', 'bios'): 1,\n",
       "         ('after', 'bios', 'update'): 1,\n",
       "         ('bios', 'update', 'power'): 1,\n",
       "         ('update', 'power', 'settings'): 1,\n",
       "         ('power', 'settings', 'unchanged'): 1,\n",
       "         ('settings', 'unchanged', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'permission'): 1,\n",
       "         ('<s>', 'permission', 'denied'): 1,\n",
       "         ('permission', 'denied', 'accessing'): 1,\n",
       "         ('denied', 'accessing', 'shared'): 1,\n",
       "         ('accessing', 'shared', 'drive'): 1,\n",
       "         ('shared', 'drive', 'though'): 1,\n",
       "         ('drive', 'though', 'in'): 1,\n",
       "         ('though', 'in', 'correct'): 1,\n",
       "         ('in', 'correct', 'group'): 1,\n",
       "         ('correct', 'group', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'user'): 1,\n",
       "         ('<s>', 'user', 'interface'): 1,\n",
       "         ('user', 'interface', 'unresponsive'): 1,\n",
       "         ('interface', 'unresponsive', 'freezing'): 1,\n",
       "         ('unresponsive', 'freezing', 'on'): 1,\n",
       "         ('freezing', 'on', 'interactions'): 1,\n",
       "         ('on', 'interactions', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'monitoring'): 1,\n",
       "         ('<s>', 'monitoring', 'system'): 1,\n",
       "         ('monitoring', 'system', 'alert'): 1,\n",
       "         ('system', 'alert', 'threshold'): 1,\n",
       "         ('alert', 'threshold', 'breached'): 1,\n",
       "         ('threshold', 'breached', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'queue'): 1,\n",
       "         ('<s>', 'queue', 'full'): 1,\n",
       "         ('queue', 'full', 'message'): 1,\n",
       "         ('full', 'message', 'processing'): 1,\n",
       "         ('message', 'processing', 'stalled'): 1,\n",
       "         ('processing', 'stalled', '</s>'): 1,\n",
       "         ('<s>', 'api', 'key'): 1,\n",
       "         ('api', 'key', 'invalid'): 1,\n",
       "         ('key', 'invalid', 'access'): 1,\n",
       "         ('invalid', 'access', 'denied'): 1,\n",
       "         ('access', 'denied', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'cpu'): 1,\n",
       "         ('<s>', 'cpu', 'utilization'): 1,\n",
       "         ('cpu', 'utilization', 'spiking'): 1,\n",
       "         ('utilization', 'spiking', 'abnormal'): 1,\n",
       "         ('spiking', 'abnormal', 'process'): 1,\n",
       "         ('abnormal', 'process', 'activity'): 1,\n",
       "         ('process', 'activity', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'certificate'): 1,\n",
       "         ('<s>', 'certificate', 'expired'): 1,\n",
       "         ('certificate', 'expired', 'secure'): 1,\n",
       "         ('expired', 'secure', 'connection'): 1,\n",
       "         ('secure', 'connection', 'failed'): 1,\n",
       "         ('connection', 'failed', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'memory'): 1,\n",
       "         ('<s>', 'memory', 'leak'): 1,\n",
       "         ('memory', 'leak', 'detected'): 1,\n",
       "         ('leak', 'detected', 'service'): 1,\n",
       "         ('detected', 'service', 'restarting'): 1,\n",
       "         ('service', 'restarting', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'push'): 1,\n",
       "         ('<s>', 'push', 'notifications'): 1,\n",
       "         ('push', 'notifications', 'not'): 1,\n",
       "         ('notifications', 'not', 'working'): 1,\n",
       "         ('not', 'working', 'on'): 1,\n",
       "         ('working', 'on', 'android'): 1,\n",
       "         ('on', 'android', 'app'): 1,\n",
       "         ('android', 'app', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'email'): 1,\n",
       "         ('<s>', 'email', 'delivery'): 1,\n",
       "         ('email', 'delivery', 'delayed'): 1,\n",
       "         ('delivery', 'delayed', 'messages'): 1,\n",
       "         ('delayed', 'messages', 'queued'): 1,\n",
       "         ('messages', 'queued', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'teams'): 1,\n",
       "         ('<s>', 'teams', 'calls'): 1,\n",
       "         ('teams', 'calls', 'choppy'): 1,\n",
       "         ('calls', 'choppy', 'audio'): 1,\n",
       "         ('choppy', 'audio', 'jitter'): 1,\n",
       "         ('audio', 'jitter', 'high'): 1,\n",
       "         ('jitter', 'high', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'billing'): 1,\n",
       "         ('<s>', 'billing', 'discrepancy'): 1,\n",
       "         ('billing', 'discrepancy', 'incorrect'): 1,\n",
       "         ('discrepancy', 'incorrect', 'invoice'): 1,\n",
       "         ('incorrect', 'invoice', 'generated'): 1,\n",
       "         ('invoice', 'generated', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'dns'): 1,\n",
       "         ('<s>', 'dns', 'resolution'): 1,\n",
       "         ('dns', 'resolution', 'failing'): 1,\n",
       "         ('resolution', 'failing', 'domain'): 1,\n",
       "         ('failing', 'domain', 'not'): 1,\n",
       "         ('domain', 'not', 'found'): 1,\n",
       "         ('not', 'found', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'container'): 1,\n",
       "         ('<s>', 'container', 'exited'): 1,\n",
       "         ('container', 'exited', 'unexpectedly'): 1,\n",
       "         ('exited', 'unexpectedly', 'check'): 1,\n",
       "         ('unexpectedly', 'check', 'logs'): 1,\n",
       "         ('check', 'logs', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'storage'): 1,\n",
       "         ('<s>', 'storage', 'quota'): 1,\n",
       "         ('storage', 'quota', 'exceeded'): 1,\n",
       "         ('quota', 'exceeded', 'cannot'): 1,\n",
       "         ('exceeded', 'cannot', 'upload'): 1,\n",
       "         ('cannot', 'upload', 'files'): 1,\n",
       "         ('upload', 'files', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'load'): 1,\n",
       "         ('<s>', 'load', 'balancer'): 1,\n",
       "         ('load', 'balancer', 'misconfigured'): 1,\n",
       "         ('balancer', 'misconfigured', 'traffic'): 1,\n",
       "         ('misconfigured', 'traffic', 'routing'): 1,\n",
       "         ('traffic', 'routing', 'issues'): 1,\n",
       "         ('routing', 'issues', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'data'): 1,\n",
       "         ('<s>', 'data', 'synchronization'): 1,\n",
       "         ('data', 'synchronization', 'error'): 1,\n",
       "         ('synchronization', 'error', 'inconsistent'): 1,\n",
       "         ('error', 'inconsistent', 'records'): 1,\n",
       "         ('inconsistent', 'records', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'backup'): 1,\n",
       "         ('<s>', 'backup', 'process'): 1,\n",
       "         ('backup', 'process', 'failed'): 1,\n",
       "         ('process', 'failed', 'data'): 1,\n",
       "         ('failed', 'data', 'integrity'): 1,\n",
       "         ('data', 'integrity', 'compromised'): 1,\n",
       "         ('integrity', 'compromised', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'authentication'): 1,\n",
       "         ('<s>', 'authentication', 'failed'): 1,\n",
       "         ('authentication', 'failed', 'invalid'): 1,\n",
       "         ('failed', 'invalid', 'credentials'): 1,\n",
       "         ('invalid', 'credentials', 'provided'): 1,\n",
       "         ('credentials', 'provided', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'disk'): 1,\n",
       "         ('<s>', 'disk', 'space'): 1,\n",
       "         ('disk', 'space', 'low'): 1,\n",
       "         ('space', 'low', 'performance'): 1,\n",
       "         ('low', 'performance', 'degraded'): 1,\n",
       "         ('performance', 'degraded', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'encryption'): 1,\n",
       "         ('<s>', 'encryption', 'key'): 1,\n",
       "         ('encryption', 'key', 'missing'): 1,\n",
       "         ('key', 'missing', 'secure'): 1,\n",
       "         ('missing', 'secure', 'communication'): 1,\n",
       "         ('secure', 'communication', 'impossible'): 1,\n",
       "         ('communication', 'impossible', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'firmware'): 1,\n",
       "         ('<s>', 'firmware', 'update'): 1,\n",
       "         ('firmware', 'update', 'failed'): 1,\n",
       "         ('update', 'failed', 'device'): 1,\n",
       "         ('failed', 'device', 'unresponsive'): 1,\n",
       "         ('device', 'unresponsive', '</s>'): 1,\n",
       "         ('<s>', 'api', 'requests'): 1,\n",
       "         ('api', 'requests', 'timeout'): 1,\n",
       "         ('requests', 'timeout', 'when'): 1,\n",
       "         ('timeout', 'when', 'latency'): 1,\n",
       "         ('when', 'latency', 'spikes'): 1,\n",
       "         ('latency', 'spikes', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'vpn'): 1,\n",
       "         ('<s>', 'vpn', 'disconnects'): 1,\n",
       "         ('vpn', 'disconnects', 'frequently'): 1,\n",
       "         ('disconnects', 'frequently', 'after'): 1,\n",
       "         ('frequently', 'after', 'windows'): 1,\n",
       "         ('after', 'windows', 'update'): 1,\n",
       "         ('windows', 'update', '</s>'): 1,\n",
       "         ('<s>', '<s>', 'scheduler'): 1,\n",
       "         ('<s>', 'scheduler', 'failed'): 1,\n",
       "         ('scheduler', 'failed', 'tasks'): 1,\n",
       "         ('failed', 'tasks', 'not'): 1,\n",
       "         ('tasks', 'not', 'executing'): 1,\n",
       "         ('not', 'executing', '</s>'): 1})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ba7c8",
   "metadata": {},
   "source": [
    "## 5) Add-k smoothing and probability function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed806986",
   "metadata": {},
   "source": [
    "Add-k smoothing (a common baseline):\n",
    "\\na) Add *k* to every possible next word count  \n",
    "b) Normalize by context_count + k * |V|\n",
    "\n",
    "P_k(w|h) = (count(h,w) + k) / (count(h) + k*|V|)\n",
    "\n",
    "Where V is the vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de565994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_addk(ngram: Tuple[str, ...], ngram_counts: Dict[Tuple[str, ...], int], context_counts: Dict[Tuple[str, ...], int], V: int, k: float = 1.0) -> float:\n",
    "    # (count(h,w) + k) / (count(h) + k*|V|)\n",
    "    if len(ngram) == 1: # Unigram probability\n",
    "        word = ngram[0]\n",
    "        total_words_plus_start = context_counts[tuple()] if tuple() in context_counts else sum(ngram_counts.values())\n",
    "\n",
    "        return (ngram_counts.get(ngram, 0) + k) / (total_words_plus_start + k * V)\n",
    "    else:\n",
    "        context = ngram[:-1]\n",
    "        numerator = ngram_counts.get(ngram, 0) + k\n",
    "        denominator = context_counts.get(context, 0) + k * V\n",
    "        if denominator == 0:\n",
    "            return 1e-10\n",
    "        return numerator / denominator\n",
    "\n",
    "\n",
    "uni_counts, uni_ctx = train_ngrams_counts(train_texts, 1, vocab)\n",
    "bi_counts, bi_ctx = train_ngrams_counts(train_texts, 2, vocab)\n",
    "tri_counts, tri_ctx = train_ngrams_counts(train_texts, 3, vocab)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6deec",
   "metadata": {},
   "source": [
    "## 6) Evaluate: cross-entropy and perplexity on test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8426d9",
   "metadata": {},
   "source": [
    "We evaluate an LM by how well it predicts held-out text.\n",
    "\n",
    "Cross-entropy (average negative log probability):\n",
    "H = - (1/N) * sum log2 P(w_i | context)\n",
    "\n",
    "Perplexity:\n",
    "PP = 2^H\n",
    "\n",
    "Lower perplexity is better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c2d03099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(test_texts: List[str], n: int,\n",
    "               ngram_counts: Dict[Tuple[str, ...], int],\n",
    "               context_counts: Dict[Tuple[str, ...], int],\n",
    "               vocab: set,\n",
    "               delta: float = 0.0) -> float:\n",
    "    N = 0  # total number of tokens\n",
    "    log_prob_sum = 0.0  # sum of log probabilities\n",
    "\n",
    "    V = len(vocab)\n",
    "\n",
    "    for t in test_texts:\n",
    "        tokens = replace_oov(tokenize(t), vocab)\n",
    "        tokens = add_boundaries(tokens, n)\n",
    "        ngrams = get_ngrams(tokens, n)\n",
    "\n",
    "        for ng in ngrams:\n",
    "            N += 1\n",
    "            context = ng[:-1]\n",
    "            count_ng = ngram_counts.get(ng, 0)\n",
    "            count_ctx = context_counts.get(context, 0)\n",
    "\n",
    "            # Apply add-delta smoothing\n",
    "            prob = (count_ng + delta) / (count_ctx + delta * V)\n",
    "            log_prob_sum += math.log(prob) if prob > 0 else float('-inf')\n",
    "\n",
    "    avg_log_prob = log_prob_sum / N\n",
    "    perplexity = math.exp(-avg_log_prob)\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "637c90a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Perplexity: 184.42\n",
      "Bigram Perplexity: 150.75\n",
      "Trigram Perplexity: 150.43\n"
     ]
    }
   ],
   "source": [
    "pp_uni = perplexity(test_texts, 1, uni_counts, uni_ctx, vocab, delta=1.0)\n",
    "pp_bi = perplexity(test_texts, 2, bi_counts, bi_ctx, vocab, delta=1.0)\n",
    "pp_tri = perplexity(test_texts, 3, tri_counts, tri_ctx, vocab, delta=1.0)\n",
    "print(f\"Unigram Perplexity: {pp_uni:.2f}\")\n",
    "print(f\"Bigram Perplexity: {pp_bi:.2f}\")\n",
    "print(f\"Trigram Perplexity: {pp_tri:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef338ce",
   "metadata": {},
   "source": [
    "## 7) Next-word prediction (top-k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d202f5",
   "metadata": {},
   "source": [
    "Given a context, compute the probability of each candidate next token and return the top-k.\n",
    "\n",
    "This mirrors:\n",
    "- autocomplete in constrained domains\n",
    "- template suggestion systems\n",
    "- command prediction in runbooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11363d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('api', 0.009162303664921465),\n",
       " ('vpn', 0.007853403141361256),\n",
       " ('disk', 0.007853403141361256)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def next_word_topk(context_tokens: List[str], n: int, ngram_counts: Dict[Tuple[str, ...], int], context_counts: Dict[Tuple[str, ...], int], vocab: set, k_smooth: float = 1.0, top_k: int = 5) -> List[Tuple[str, float]]:\n",
    "\tV = len(vocab)\n",
    "\tcontext = tuple(context_tokens[-(n-1):]) if n > 1 else tuple()\n",
    "\tcandidates = [(w, prob_addk(context + (w,), ngram_counts, context_counts, V, k=k_smooth)) for w in vocab if w not in {\"<s>\", \"</s>\"}]\n",
    "\tcandidates.sort(key=lambda x: x[1], reverse=True)\n",
    "\treturn candidates[:top_k]\n",
    "\n",
    "next_word_topk([\"<s>\"], n=2, ngram_counts=bi_counts, context_counts=bi_ctx, vocab=vocab, k_smooth=5, top_k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672e1e9",
   "metadata": {},
   "source": [
    "## 8) Simple generation (bigram or trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd41fb",
   "metadata": {},
   "source": [
    "Text generation is not the main goal in SLMs, but it helps you verify:\n",
    "- boundary handling\n",
    "- smoothing\n",
    "- OOV decisions\n",
    "\n",
    "We will sample tokens until we hit `</s>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c8d1acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGRAM: battery spiking message group geolocation audio discrepancy timeout threshold device message spiking scheduler power vpn windows resolution\n",
      "BIGRAM: when on tasks invoice <UNK> disconnects when teams denied external routing working connection detected disconnects permission unexpectedly inconsistent\n",
      "BIGRAM: interactions integrity check when domain unresponsive in when queue deployment low latency timeout notifications to teams in email\n",
      "BIGRAM: accessing 500 traffic incorrect full blocking alert provided vpn api invoice container load disk disconnects blocking executing data\n",
      "BIGRAM: spiking jitter geolocation delivery audio authentication invoice api returns to drains deployment in unchanged detected notifications requests low\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_next(context_tokens: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k_smooth: float = 0.5):\n",
    "    V = len(vocab)\n",
    "    context = tuple(context_tokens[-(n-1):]) if n > 1 else tuple()\n",
    "    words = [w for w in vocab if w != \"<s>\"]\n",
    "    probs = []\n",
    "    for w in words:\n",
    "        ng = context + (w,)\n",
    "        probs.append(prob_addk(ng, ngram_counts, context_counts, V, k=k_smooth))\n",
    "    # Normalize\n",
    "    s = sum(probs)\n",
    "    probs = [p/s for p in probs]\n",
    "    return random.choices(words, weights=probs, k=1)[0]\n",
    "\n",
    "def generate(n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, max_len: int = 20, k_smooth: float = 0.5):\n",
    "    tokens = [\"<s>\"]*(n-1) if n > 1 else []\n",
    "    out = []\n",
    "    for _ in range(max_len):\n",
    "        w = sample_next(tokens, n, ngram_counts, context_counts, vocab, k_smooth=k_smooth)\n",
    "        if w == \"</s>\":\n",
    "            break\n",
    "        out.append(w)\n",
    "        tokens.append(w)\n",
    "    return \" \".join(out)\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"BIGRAM:\", generate(2, bi_counts, bi_ctx, vocab, max_len=18))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db5405",
   "metadata": {},
   "source": [
    "## 9) Model comparison: effect of n and smoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7486afd",
   "metadata": {},
   "source": [
    "Try different `k` values. Notes:\n",
    "- `k=1.0` is Laplace smoothing (often too strong)\n",
    "- smaller `k` (like 0.1 to 0.5) is often better\n",
    "\n",
    "In real corpora, trigrams often beat bigrams, but require more data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb25609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be49abe",
   "metadata": {},
   "source": [
    "## Exercises (do these during lab)\n",
    "1) Add 20 more realistic domain sentences to the corpus and re-run training/evaluation.  \n",
    "2) Change `min_count` (OOV threshold) and explain how perplexity changes.  \n",
    "3) Implement **backoff**: if a trigram is unseen, fall back to bigram; if unseen, fall back to unigram.  \n",
    "4) Create a function that returns **top-5 next words** given a phrase like: `\"user cannot\"`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be88da",
   "metadata": {},
   "source": [
    "Changing the Out-of-Vocabulary threshold from two to one drastically increases the perplexity; Unigram goes from 2.20 to 168.83, Bigram goes from 2.91 to 150.75, and Trigram goes from 3.20 to 150.43 (both of these applies to the expanded corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba38b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_backoff(ngram: Tuple[str, ...],\n",
    "                        uni_counts: Dict[Tuple[str, ...], int],\n",
    "                        uni_ctx: Dict[Tuple[str, ...], int],\n",
    "                        bi_counts: Dict[Tuple[str, ...], int],\n",
    "                        bi_ctx: Dict[Tuple[str, ...], int],\n",
    "                        tri_counts: Dict[Tuple[str, ...], int],\n",
    "                        tri_ctx: Dict[Tuple[str, ...], int],\n",
    "                        vocab_size: int,\n",
    "                        k_smooth: float = 0.5) -> float:\n",
    "    n = len(ngram)\n",
    "\n",
    "    if n == 3:\n",
    "        # Check if trigram exists (count > 0). If so, use its probability.\n",
    "        if tri_counts.get(ngram, 0) > 0:\n",
    "            return prob_addk(ngram, tri_counts, tri_ctx, vocab_size, k=k_smooth)\n",
    "        else:\n",
    "            # Otherwise, fall back to bigram (last two tokens).\n",
    "            return simple_backoff(ngram[1:], uni_counts, uni_ctx, bi_counts, bi_ctx, tri_counts, tri_ctx, vocab_size, k_smooth)\n",
    "    elif n == 2:\n",
    "        # Check if bigram exists (count > 0). If so, use its probability.\n",
    "        if bi_counts.get(ngram, 0) > 0:\n",
    "            return prob_addk(ngram, bi_counts, bi_ctx, vocab_size, k=k_smooth)\n",
    "        else:\n",
    "            # Otherwise, fall back to unigram (last token).\n",
    "            return simple_backoff(ngram[1:], uni_counts, uni_ctx, bi_counts, bi_ctx, tri_counts, tri_ctx, vocab_size, k_smooth)\n",
    "    elif n == 1:\n",
    "        # Base case: unigram probability. No further backoff.\n",
    "        return prob_addk(ngram, uni_counts, uni_ctx, vocab_size, k=k_smooth)\n",
    "    else:\n",
    "        # Should not be reached for valid n-grams (n=1, 2, or 3)\n",
    "        return 1e-10 # Return a very small probability for unsupported n-gram lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0539f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perxplexity function must be modified to consider backoff algorithm.\n",
    "def backoff_perplexity(test_texts: List[str],\n",
    "                            n_model: int,\n",
    "                            uni_counts: Dict[Tuple[str, ...], int],\n",
    "                            uni_ctx: Dict[Tuple[str, ...], int],\n",
    "                            bi_counts: Dict[Tuple[str, ...], int],\n",
    "                            bi_ctx: Dict[Tuple[str, ...], int],\n",
    "                            tri_counts: Dict[Tuple[str, ...], int],\n",
    "                            tri_ctx: Dict[Tuple[str, ...], int],\n",
    "                            vocab: set,\n",
    "                            k_smooth: float = 0.5) -> float:\n",
    "    N = 0  # total number of tokens\n",
    "    log_prob_sum = 0.0  # sum of log probabilities\n",
    "\n",
    "    V = len(vocab)\n",
    "\n",
    "    for t in test_texts:\n",
    "        tokens = replace_oov(tokenize(t), vocab)\n",
    "        tokens = add_boundaries(tokens, n_model)\n",
    "        \n",
    "        # When calculating perplexity for an n-gram model, we are interested in P(w_i | w_{i-1}...w_{i-n+1})\n",
    "        # So we iterate through the tokens to form n-grams where the last token is the one being predicted.\n",
    "        # The `get_ngrams` function gives us (w_{i-n+1}, ..., w_i)\n",
    "        for i in range(len(tokens) - n_model + 1):\n",
    "            ngram_to_evaluate = tuple(tokens[i : i + n_model])\n",
    "            \n",
    "            # We use prob_backoff_simple here\n",
    "            prob = simple_backoff(ngram_to_evaluate,\n",
    "                                     uni_counts, uni_ctx,\n",
    "                                     bi_counts, bi_ctx,\n",
    "                                     tri_counts, tri_ctx,\n",
    "                                     V, k_smooth)\n",
    "\n",
    "            # For each word in the test set (excluding initial start tokens for context),\n",
    "            # we count it as N. So for an n-gram (w_1, ..., w_n), w_n is the word being predicted.\n",
    "            # The boundary token '</s>' also counts as a word.\n",
    "            if ngram_to_evaluate[-1] != '<s>': # Don't count '<s>' as N for perplexity calculation\n",
    "                N += 1\n",
    "                log_prob_sum += math.log2(prob) if prob > 0 else float('-inf')\n",
    "    \n",
    "    # Ensure N is not zero to avoid division by zero\n",
    "    if N == 0: \n",
    "        return float('inf')\n",
    "\n",
    "    avg_log_prob = log_prob_sum / N\n",
    "    perplexity_score = 2 ** (-avg_log_prob)\n",
    "    return perplexity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6b68c7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Perplexity (Add-k only): 150.75\n",
      "Trigram Perplexity (Add-k only): 150.43\n",
      "Bigram Perplexity (with backoff): 241.32\n",
      "Trigram Perplexity (with backoff): 241.32\n"
     ]
    }
   ],
   "source": [
    "pp_bi_backoff = backoff_perplexity(test_texts, 2, uni_counts, uni_ctx, bi_counts, bi_ctx, tri_counts, tri_ctx, vocab, k_smooth=0.5)\n",
    "pp_tri_backoff = backoff_perplexity(test_texts, 3, uni_counts, uni_ctx, bi_counts, bi_ctx, tri_counts, tri_ctx, vocab, k_smooth=0.5)\n",
    "\n",
    "print(f\"Bigram Perplexity (Add-k only): {pp_bi:.2f}\")\n",
    "print(f\"Trigram Perplexity (Add-k only): {pp_tri:.2f}\")\n",
    "print(f\"Bigram Perplexity (with backoff): {pp_bi_backoff:.2f}\")\n",
    "print(f\"Trigram Perplexity (with backoff): {pp_tri_backoff:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e17a4789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 next words for 'user cannot' (trigram model, k_smooth=0.5):\n",
      "- restarting: 0.0068\n",
      "- jitter: 0.0068\n",
      "- processing: 0.0068\n",
      "- update: 0.0068\n",
      "- domain: 0.0068\n",
      "\n",
      "Top 5 next words for 'mfa' (bigram model, k_smooth=0.5):\n",
      "- restarting: 0.0068\n",
      "- jitter: 0.0068\n",
      "- processing: 0.0068\n",
      "- update: 0.0068\n",
      "- domain: 0.0068\n",
      "\n",
      "Top 5 next words for 'disconnected' (bigram model, k_smooth=0.5): This word might be OOV.\n",
      "- restarting: 0.0068\n",
      "- jitter: 0.0068\n",
      "- processing: 0.0068\n",
      "- update: 0.0068\n",
      "- domain: 0.0068\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_next_words_from_phrase(phrase: str, n_model: int, vocab: set,\n",
    "                                     uni_counts: Dict[Tuple[str, ...], int],\n",
    "                                     uni_ctx: Dict[Tuple[str, ...], int],\n",
    "                                     bi_counts: Dict[Tuple[str, ...], int],\n",
    "                                     bi_ctx: Dict[Tuple[str, ...], int],\n",
    "                                     tri_counts: Dict[Tuple[str, ...], int],\n",
    "                                     tri_ctx: Dict[Tuple[str, ...], int],\n",
    "                                     k_smooth: float = 1.0, top_k: int = 5) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Given a phrase, returns the top-k next words predicted by an n-gram model.\n",
    "    The prediction uses the specified n-gram model (unigram, bigram, or trigram).\n",
    "    \"\"\"\n",
    "    # Helper to get the correct counts based on n_model\n",
    "    def _get_ngram_models(n_val: int):\n",
    "        if n_val == 1:\n",
    "            return uni_counts, uni_ctx\n",
    "        elif n_val == 2:\n",
    "            return bi_counts, bi_ctx\n",
    "        elif n_val == 3:\n",
    "            return tri_counts, tri_ctx\n",
    "        else:\n",
    "            raise ValueError(\"n_model must be 1, 2, or 3\")\n",
    "\n",
    "    # 1. Tokenize and handle OOV for the input phrase\n",
    "    phrase_tokens = tokenize(phrase)\n",
    "    phrase_tokens_oov = replace_oov(phrase_tokens, vocab)\n",
    "\n",
    "    # 2. Get the context for prediction\n",
    "    # For an n-gram model, the context length is n-1.\n",
    "    # e.g., for trigram (n_model=3), context is last 2 words.\n",
    "    # If the phrase is shorter than n-1, use what's available.\n",
    "    context_tokens = phrase_tokens_oov[-(n_model - 1):] if n_model > 1 else []\n",
    "\n",
    "    # 3. Get the correct n-gram counts and context counts for the specified model order\n",
    "    ngram_counts, context_counts = _get_ngram_models(n_model)\n",
    "\n",
    "    # 4. Use the existing next_word_topk function (from cell 11363d81)\n",
    "    return next_word_topk(context_tokens, n_model, ngram_counts, context_counts, vocab, k_smooth, top_k)\n",
    "\n",
    "# Examples of usage\n",
    "# Using k_smooth=0.5 as it was used in the generate function previously.\n",
    "\n",
    "print(\"Top 5 next words for 'user cannot' (trigram model, k_smooth=0.5):\")\n",
    "top_words_tri = get_top_n_next_words_from_phrase(\"user cannot\", 3, vocab,\n",
    "                                                uni_counts, uni_ctx,\n",
    "                                                bi_counts, bi_ctx,\n",
    "                                                tri_counts, tri_ctx, k_smooth=0.5, top_k=5)\n",
    "for word, prob in top_words_tri:\n",
    "    print(f\"- {word}: {prob:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 next words for 'mfa' (bigram model, k_smooth=0.5):\")\n",
    "top_words_bi = get_top_n_next_words_from_phrase(\"mfa\", 2, vocab,\n",
    "                                               uni_counts, uni_ctx,\n",
    "                                               bi_counts, bi_ctx,\n",
    "                                               tri_counts, tri_ctx, k_smooth=0.5, top_k=5)\n",
    "for word, prob in top_words_bi:\n",
    "    print(f\"- {word}: {prob:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 next words for 'disconnected' (bigram model, k_smooth=0.5): This word might be OOV.\")\n",
    "top_words_bi_oov = get_top_n_next_words_from_phrase(\"disconnected\", 2, vocab,\n",
    "                                                  uni_counts, uni_ctx,\n",
    "                                                  bi_counts, bi_ctx,\n",
    "                                                  tri_counts, tri_ctx, k_smooth=0.5, top_k=5)\n",
    "for word, prob in top_words_bi_oov:\n",
    "    print(f\"- {word}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c559f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
